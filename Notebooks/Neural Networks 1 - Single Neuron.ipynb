{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c03583b3",
   "metadata": {},
   "source": [
    "# Neural Networks from Scratch - Part 1: The Single Neuron\n",
    "\n",
    "Welcome to the fascinating world of Neural Networks! In this first notebook, we'll start simple and build a single artificial neuron from scratch. You'll learn how a neuron thinks, makes decisions, and processes information - all explained in plain English with beautiful animations.\n",
    "\n",
    "## What You'll Learn:\n",
    "- What is an artificial neuron?\n",
    "- How neurons process information\n",
    "- Weights, biases, and activation functions\n",
    "- Programming a neuron from scratch\n",
    "- Making your first predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc45336",
   "metadata": {},
   "source": [
    "## Step 1: Setting Up Our Environment\n",
    "\n",
    "Let's import the libraries we need. We'll use minimal dependencies to understand everything from the ground up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from manim import *\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducible results\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Environment set up successfully!\")\n",
    "print(\"Ready to build our first neuron! üß†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814532f",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the Inspiration\n",
    "\n",
    "Artificial neurons are inspired by biological neurons in our brain. Let's understand the basic concept before we start coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple example to understand what a neuron does\n",
    "print(\"üß† BIOLOGICAL NEURON vs ARTIFICIAL NEURON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nBiological Neuron:\")\n",
    "print(\"‚Ä¢ Receives signals from other neurons\")\n",
    "print(\"‚Ä¢ Processes these signals\")\n",
    "print(\"‚Ä¢ Decides whether to 'fire' (send signal)\")\n",
    "print(\"‚Ä¢ Sends signal to other neurons\")\n",
    "\n",
    "print(\"\\nArtificial Neuron:\")\n",
    "print(\"‚Ä¢ Receives numbers as inputs\")\n",
    "print(\"‚Ä¢ Multiplies inputs by weights\")\n",
    "print(\"‚Ä¢ Adds them up (+ bias)\")\n",
    "print(\"‚Ä¢ Applies activation function\")\n",
    "print(\"‚Ä¢ Outputs a number\")\n",
    "\n",
    "print(\"\\nüí° Key Insight: A neuron is just a mathematical function!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765c6ed",
   "metadata": {},
   "source": [
    "## Step 3: Our First Simple Example\n",
    "\n",
    "Let's create a neuron that helps decide whether to go outside based on weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example: \"Should I go outside?\"\n",
    "# Inputs: [temperature, sunshine, wind_speed]\n",
    "# Output: go_outside (0 = stay inside, 1 = go outside)\n",
    "\n",
    "def simple_neuron_example():\n",
    "    print(\"üå§Ô∏è  WEATHER DECISION NEURON\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Example weather data\n",
    "    weather_conditions = [\n",
    "        {\"temp\": 25, \"sunshine\": 8, \"wind\": 2, \"description\": \"Perfect day\"},\n",
    "        {\"temp\": 5, \"sunshine\": 2, \"wind\": 8, \"description\": \"Cold and windy\"},\n",
    "        {\"temp\": 30, \"sunshine\": 9, \"wind\": 1, \"description\": \"Hot and sunny\"},\n",
    "        {\"temp\": 15, \"sunshine\": 3, \"wind\": 6, \"description\": \"Cool and cloudy\"}\n",
    "    ]\n",
    "    \n",
    "    # Our neuron's \"opinion\" (weights)\n",
    "    # How much does each factor matter?\n",
    "    weight_temp = 0.3      # Temperature matters moderately\n",
    "    weight_sunshine = 0.5  # Sunshine matters a lot!\n",
    "    weight_wind = -0.4     # Wind is bad (negative weight)\n",
    "    bias = -5              # General preference to stay inside\n",
    "    \n",
    "    print(f\"Neuron's preferences (weights):\")\n",
    "    print(f\"‚Ä¢ Temperature importance: {weight_temp}\")\n",
    "    print(f\"‚Ä¢ Sunshine importance: {weight_sunshine}\")\n",
    "    print(f\"‚Ä¢ Wind importance: {weight_wind} (negative = bad)\")\n",
    "    print(f\"‚Ä¢ Base preference (bias): {bias}\\n\")\n",
    "    \n",
    "    for weather in weather_conditions:\n",
    "        # This is what our neuron does:\n",
    "        # 1. Multiply each input by its weight\n",
    "        # 2. Add them all up\n",
    "        # 3. Add the bias\n",
    "        \n",
    "        decision_score = (weather[\"temp\"] * weight_temp + \n",
    "                         weather[\"sunshine\"] * weight_sunshine + \n",
    "                         weather[\"wind\"] * weight_wind + \n",
    "                         bias)\n",
    "        \n",
    "        # 4. Apply activation function (simple threshold)\n",
    "        go_outside = 1 if decision_score > 0 else 0\n",
    "        \n",
    "        print(f\"{weather['description']:15} | Score: {decision_score:6.1f} | Decision: {'GO OUT! üåû' if go_outside else 'Stay in üè†'}\")\n",
    "\n",
    "simple_neuron_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2cd6ea",
   "metadata": {},
   "source": [
    "## Step 4: Building Our Neuron Class\n",
    "\n",
    "Now let's code a proper neuron class that we can reuse. We'll build it step by step so you understand every line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984607ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuron:\n",
    "    \"\"\"\n",
    "    A simple artificial neuron that processes inputs and produces output.\n",
    "    \n",
    "    The neuron:\n",
    "    1. Takes inputs (numbers)\n",
    "    2. Multiplies each input by a weight\n",
    "    3. Adds all weighted inputs together\n",
    "    4. Adds a bias term\n",
    "    5. Applies an activation function\n",
    "    6. Returns the output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_inputs):\n",
    "        \"\"\"\n",
    "        Initialize the neuron with random weights and bias.\n",
    "        \n",
    "        Args:\n",
    "            num_inputs: How many input numbers this neuron expects\n",
    "        \"\"\"\n",
    "        # Initialize weights randomly (small values)\n",
    "        self.weights = np.random.randn(num_inputs) * 0.5\n",
    "        \n",
    "        # Initialize bias to zero\n",
    "        self.bias = 0.0\n",
    "        \n",
    "        print(f\"üß† Neuron created with {num_inputs} inputs\")\n",
    "        print(f\"   Initial weights: {self.weights.round(3)}\")\n",
    "        print(f\"   Initial bias: {self.bias}\")\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Process inputs through the neuron (forward pass).\n",
    "        \n",
    "        This is the core of what a neuron does!\n",
    "        \"\"\"\n",
    "        # Step 1: Multiply inputs by weights (this is our dot product!)\n",
    "        weighted_sum = np.dot(inputs, self.weights)\n",
    "        \n",
    "        # Step 2: Add bias\n",
    "        z = weighted_sum + self.bias\n",
    "        \n",
    "        # Step 3: Apply activation function (sigmoid)\n",
    "        output = self.sigmoid(z)\n",
    "        \n",
    "        return output, z  # Return both output and raw sum\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        Sigmoid activation function.\n",
    "        \n",
    "        This function:\n",
    "        - Takes any number (positive or negative)\n",
    "        - Returns a number between 0 and 1\n",
    "        - Creates smooth, S-shaped curve\n",
    "        \"\"\"\n",
    "        # Prevent overflow for very large numbers\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def set_weights_and_bias(self, weights, bias):\n",
    "        \"\"\"\n",
    "        Manually set weights and bias (useful for examples).\n",
    "        \"\"\"\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = bias\n",
    "        print(f\"‚úèÔ∏è  Weights set to: {self.weights}\")\n",
    "        print(f\"   Bias set to: {self.bias}\")\n",
    "\n",
    "# Test our neuron!\n",
    "print(\"Let's create our first neuron!\\n\")\n",
    "neuron = SimpleNeuron(num_inputs=3)\n",
    "\n",
    "# Test with some inputs\n",
    "test_input = [1.0, 2.0, -0.5]\n",
    "output, raw_sum = neuron.forward(test_input)\n",
    "\n",
    "print(f\"\\nüß™ Testing the neuron:\")\n",
    "print(f\"   Input: {test_input}\")\n",
    "print(f\"   Raw sum (z): {raw_sum:.3f}\")\n",
    "print(f\"   Final output: {output:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7720b09",
   "metadata": {},
   "source": [
    "## Step 5: Understanding Activation Functions\n",
    "\n",
    "The activation function is crucial - it decides when the neuron should \"fire\". Let's explore different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize different activation functions\n",
    "def plot_activation_functions():\n",
    "    \"\"\"\n",
    "    Show different activation functions and explain what they do.\n",
    "    \"\"\"\n",
    "    z_values = np.linspace(-10, 10, 200)\n",
    "    \n",
    "    # Different activation functions\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def relu(z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def tanh(z):\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    def step(z):\n",
    "        return (z > 0).astype(float)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add each activation function\n",
    "    functions = [\n",
    "        (sigmoid, \"Sigmoid\", \"blue\", \"Smooth, outputs 0-1\"),\n",
    "        (relu, \"ReLU\", \"red\", \"Simple, outputs 0 or input\"),\n",
    "        (tanh, \"Tanh\", \"green\", \"Smooth, outputs -1 to 1\"),\n",
    "        (step, \"Step\", \"orange\", \"Binary, outputs 0 or 1\")\n",
    "    ]\n",
    "    \n",
    "    for func, name, color, description in functions:\n",
    "        y_values = func(z_values)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=z_values,\n",
    "            y=y_values,\n",
    "            mode='lines',\n",
    "            name=f\"{name}: {description}\",\n",
    "            line=dict(color=color, width=3)\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Activation Functions: How Neurons Make Decisions\",\n",
    "        xaxis_title=\"Input to Activation Function (z)\",\n",
    "        yaxis_title=\"Output\",\n",
    "        hovermode='x unified',\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Show the plot\n",
    "activation_plot = plot_activation_functions()\n",
    "activation_plot.show()\n",
    "\n",
    "print(\"\\nüìä Activation Function Comparison:\")\n",
    "print(\"‚Ä¢ Sigmoid: Smooth probability-like output (0 to 1)\")\n",
    "print(\"‚Ä¢ ReLU: Simple and fast, only positive outputs\")\n",
    "print(\"‚Ä¢ Tanh: Like sigmoid but ranges from -1 to 1\")\n",
    "print(\"‚Ä¢ Step: Binary decision, like an on/off switch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e2617",
   "metadata": {},
   "source": [
    "## Step 6: Interactive Neuron Playground\n",
    "\n",
    "Let's create an interactive example where you can see how changing weights affects the neuron's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67685377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_playground(inputs, weight_ranges, bias_range):\n",
    "    \"\"\"\n",
    "    Interactive playground to understand how weights and bias affect output.\n",
    "    \"\"\"\n",
    "    print(\"üéÆ NEURON PLAYGROUND\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"Fixed inputs: {inputs}\")\n",
    "    print(\"\\nLet's see how different weights change the output:\\n\")\n",
    "    \n",
    "    # Test different weight combinations\n",
    "    test_cases = [\n",
    "        ([1.0, 1.0, 1.0], 0.0, \"All weights equal\"),\n",
    "        ([2.0, 0.0, 0.0], 0.0, \"Only first input matters\"),\n",
    "        ([0.0, 2.0, 0.0], 0.0, \"Only second input matters\"),\n",
    "        ([1.0, 1.0, 1.0], 2.0, \"Positive bias (easier to activate)\"),\n",
    "        ([1.0, 1.0, 1.0], -2.0, \"Negative bias (harder to activate)\"),\n",
    "        ([-1.0, -1.0, -1.0], 0.0, \"All negative weights\")\n",
    "    ]\n",
    "    \n",
    "    neuron = SimpleNeuron(len(inputs))\n",
    "    \n",
    "    for weights, bias, description in test_cases:\n",
    "        neuron.set_weights_and_bias(weights, bias)\n",
    "        output, z = neuron.forward(inputs)\n",
    "        \n",
    "        print(f\"{description:30} | Raw sum: {z:6.2f} | Output: {output:.3f}\")\n",
    "    \n",
    "    print(\"\\nüí° Notice how:\")\n",
    "    print(\"‚Ä¢ Positive weights amplify inputs\")\n",
    "    print(\"‚Ä¢ Negative weights diminish inputs\")\n",
    "    print(\"‚Ä¢ Bias shifts the decision threshold\")\n",
    "    print(\"‚Ä¢ Sigmoid keeps output between 0 and 1\")\n",
    "\n",
    "# Run the playground\n",
    "test_inputs = [0.5, 1.5, -0.8]\n",
    "neuron_playground(test_inputs, [(-2, 2), (-2, 2), (-2, 2)], (-3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f8ea0",
   "metadata": {},
   "source": [
    "## Step 7: Manim Animations\n",
    "\n",
    "Now let's create beautiful animations to visualize how a neuron works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17232b9b",
   "metadata": {},
   "source": [
    "### Animation 1: Neuron Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%manim -qm -v WARNING NeuronStructure\n",
    "\n",
    "class NeuronStructure(Scene):\n",
    "    def construct(self):\n",
    "        # Title\n",
    "        title = Text(\"Anatomy of an Artificial Neuron\", font_size=42, color=BLUE)\n",
    "        self.play(Write(title))\n",
    "        self.wait(1)\n",
    "        self.play(title.animate.to_edge(UP))\n",
    "        \n",
    "        # Create input nodes\n",
    "        input_positions = [[-4, 2, 0], [-4, 0, 0], [-4, -2, 0]]\n",
    "        inputs = []\n",
    "        input_labels = []\n",
    "        \n",
    "        for i, pos in enumerate(input_positions):\n",
    "            # Input circle\n",
    "            input_node = Circle(radius=0.3, color=GREEN, fill_opacity=0.7)\n",
    "            input_node.move_to(pos)\n",
    "            inputs.append(input_node)\n",
    "            \n",
    "            # Input label\n",
    "            label = Text(f\"x{i+1}\", font_size=20, color=WHITE)\n",
    "            label.move_to(pos)\n",
    "            input_labels.append(label)\n",
    "        \n",
    "        # Create neuron (main processing unit)\n",
    "        neuron = Circle(radius=0.8, color=BLUE, fill_opacity=0.8)\n",
    "        neuron.move_to([2, 0, 0])\n",
    "        neuron_label = Text(\"Neuron\", font_size=24, color=WHITE)\n",
    "        neuron_label.move_to([2, 0, 0])\n",
    "        \n",
    "        # Create output\n",
    "        output = Circle(radius=0.3, color=RED, fill_opacity=0.7)\n",
    "        output.move_to([5, 0, 0])\n",
    "        output_label = Text(\"y\", font_size=20, color=WHITE)\n",
    "        output_label.move_to([5, 0, 0])\n",
    "        \n",
    "        # Show inputs first\n",
    "        explanation1 = Text(\"Inputs: Raw data numbers\", font_size=24, color=GREEN)\n",
    "        explanation1.to_edge(DOWN)\n",
    "        \n",
    "        self.play(Write(explanation1))\n",
    "        for inp, label in zip(inputs, input_labels):\n",
    "            self.play(Create(inp), Write(label), run_time=0.5)\n",
    "        \n",
    "        self.wait(1)\n",
    "        \n",
    "        # Show neuron\n",
    "        explanation2 = Text(\"Neuron: Processes and combines inputs\", font_size=24, color=BLUE)\n",
    "        self.play(ReplacementTransform(explanation1, explanation2))\n",
    "        self.play(Create(neuron), Write(neuron_label))\n",
    "        \n",
    "        # Create connections (weights)\n",
    "        connections = []\n",
    "        weight_labels = []\n",
    "        weights = [0.8, -0.3, 1.2]\n",
    "        \n",
    "        for i, (inp_pos, weight) in enumerate(zip(input_positions, weights)):\n",
    "            # Connection line\n",
    "            line = Line(inp_pos, [2, 0, 0], color=YELLOW)\n",
    "            connections.append(line)\n",
    "            \n",
    "            # Weight label\n",
    "            mid_point = [(inp_pos[0] + 2)/2, inp_pos[1]/2, 0]\n",
    "            w_label = Text(f\"w{i+1}={weight}\", font_size=16, color=YELLOW)\n",
    "            w_label.move_to(mid_point)\n",
    "            weight_labels.append(w_label)\n",
    "        \n",
    "        explanation3 = Text(\"Weights: How important each input is\", font_size=24, color=YELLOW)\n",
    "        self.play(ReplacementTransform(explanation2, explanation3))\n",
    "        \n",
    "        for conn, w_label in zip(connections, weight_labels):\n",
    "            self.play(Create(conn), Write(w_label), run_time=0.7)\n",
    "        \n",
    "        self.wait(1)\n",
    "        \n",
    "        # Show output\n",
    "        output_line = Line([2, 0, 0], [5, 0, 0], color=RED)\n",
    "        \n",
    "        explanation4 = Text(\"Output: Final decision or prediction\", font_size=24, color=RED)\n",
    "        self.play(ReplacementTransform(explanation3, explanation4))\n",
    "        \n",
    "        self.play(Create(output_line), Create(output), Write(output_label))\n",
    "        \n",
    "        # Show the math\n",
    "        math_formula = MathTex(\n",
    "            r\"y = \\sigma(w_1x_1 + w_2x_2 + w_3x_3 + b)\",\n",
    "            font_size=32,\n",
    "            color=WHITE\n",
    "        )\n",
    "        math_formula.move_to([0, -3, 0])\n",
    "        \n",
    "        self.play(Write(math_formula))\n",
    "        \n",
    "        # Final explanation\n",
    "        final_explanation = Text(\n",
    "            \"œÉ (sigma) = activation function (like sigmoid)\",\n",
    "            font_size=20, color=WHITE\n",
    "        )\n",
    "        final_explanation.next_to(math_formula, DOWN)\n",
    "        \n",
    "        self.play(Write(final_explanation))\n",
    "        self.wait(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5179fe",
   "metadata": {},
   "source": [
    "### Animation 2: Information Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%manim -qm -v WARNING InformationFlow\n",
    "\n",
    "class InformationFlow(Scene):\n",
    "    def construct(self):\n",
    "        # Title\n",
    "        title = Text(\"How Information Flows Through a Neuron\", font_size=38, color=BLUE)\n",
    "        self.play(Write(title))\n",
    "        self.wait(1)\n",
    "        self.play(title.animate.to_edge(UP))\n",
    "        \n",
    "        # Create the neuron structure (simplified)\n",
    "        inputs = [Circle(radius=0.2, color=GREEN, fill_opacity=0.8).move_to([-4, i, 0]) for i in [1, 0, -1]]\n",
    "        neuron = Circle(radius=0.6, color=BLUE, fill_opacity=0.8).move_to([0, 0, 0])\n",
    "        output = Circle(radius=0.2, color=RED, fill_opacity=0.8).move_to([4, 0, 0])\n",
    "        \n",
    "        # Input values\n",
    "        input_values = [2.0, -1.5, 0.8]\n",
    "        weights = [0.5, -0.3, 1.2]\n",
    "        bias = 0.1\n",
    "        \n",
    "        # Labels\n",
    "        input_labels = [Text(f\"{val}\", font_size=16, color=WHITE).move_to(inp.get_center()) \n",
    "                       for inp, val in zip(inputs, input_values)]\n",
    "        \n",
    "        # Create everything\n",
    "        for inp, label in zip(inputs, input_labels):\n",
    "            self.add(inp, label)\n",
    "        self.add(neuron, output)\n",
    "        \n",
    "        # Step 1: Show inputs\n",
    "        step1 = Text(\"Step 1: Inputs arrive at the neuron\", font_size=24, color=WHITE)\n",
    "        step1.to_edge(DOWN)\n",
    "        self.play(Write(step1))\n",
    "        \n",
    "        # Highlight inputs\n",
    "        for inp in inputs:\n",
    "            self.play(inp.animate.set_stroke(color=YELLOW, width=4), run_time=0.3)\n",
    "        \n",
    "        self.wait(1)\n",
    "        \n",
    "        # Step 2: Multiply by weights\n",
    "        step2 = Text(\"Step 2: Each input is multiplied by its weight\", font_size=24, color=WHITE)\n",
    "        self.play(ReplacementTransform(step1, step2))\n",
    "        \n",
    "        # Show calculations\n",
    "        calculations = []\n",
    "        for i, (val, weight) in enumerate(zip(input_values, weights)):\n",
    "            calc_text = Text(f\"{val} √ó {weight} = {val*weight:.2f}\", \n",
    "                           font_size=16, color=YELLOW)\n",
    "            calc_text.move_to([-2, 1-i*0.5, 0])\n",
    "            calculations.append(calc_text)\n",
    "            self.play(Write(calc_text), run_time=0.5)\n",
    "        \n",
    "        self.wait(1)\n",
    "        \n",
    "        # Step 3: Sum everything\n",
    "        step3 = Text(\"Step 3: Add all weighted inputs + bias\", font_size=24, color=WHITE)\n",
    "        self.play(ReplacementTransform(step2, step3))\n",
    "        \n",
    "        # Calculate sum\n",
    "        weighted_sum = sum(val * weight for val, weight in zip(input_values, weights))\n",
    "        total_sum = weighted_sum + bias\n",
    "        \n",
    "        sum_text = Text(f\"Sum = {weighted_sum:.2f} + {bias} = {total_sum:.2f}\", \n",
    "                       font_size=20, color=ORANGE)\n",
    "        sum_text.move_to([0, -1.5, 0])\n",
    "        \n",
    "        self.play(Write(sum_text))\n",
    "        \n",
    "        # Clear calculations\n",
    "        self.play(*[FadeOut(calc) for calc in calculations])\n",
    "        \n",
    "        self.wait(1)\n",
    "        \n",
    "        # Step 4: Apply activation function\n",
    "        step4 = Text(\"Step 4: Apply activation function (sigmoid)\", font_size=24, color=WHITE)\n",
    "        self.play(ReplacementTransform(step3, step4))\n",
    "        \n",
    "        # Calculate sigmoid\n",
    "        sigmoid_output = 1 / (1 + np.exp(-total_sum))\n",
    "        \n",
    "        sigmoid_text = Text(f\"œÉ({total_sum:.2f}) = {sigmoid_output:.3f}\", \n",
    "                          font_size=20, color=RED)\n",
    "        sigmoid_text.move_to([2, -1.5, 0])\n",
    "        \n",
    "        self.play(Write(sigmoid_text))\n",
    "        \n",
    "        # Show final output\n",
    "        output_label = Text(f\"{sigmoid_output:.3f}\", font_size=16, color=WHITE)\n",
    "        output_label.move_to(output.get_center())\n",
    "        self.play(Write(output_label))\n",
    "        \n",
    "        # Animate flow\n",
    "        flow_dot = Dot(color=YELLOW, radius=0.1)\n",
    "        flow_dot.move_to(inputs[0].get_center())\n",
    "        \n",
    "        self.play(Create(flow_dot))\n",
    "        self.play(flow_dot.animate.move_to(neuron.get_center()), run_time=1)\n",
    "        self.play(flow_dot.animate.move_to(output.get_center()), run_time=1)\n",
    "        \n",
    "        # Final message\n",
    "        final_msg = Text(\"Information transformed from inputs to meaningful output!\", \n",
    "                        font_size=20, color=GREEN)\n",
    "        self.play(ReplacementTransform(step4, final_msg))\n",
    "        \n",
    "        self.wait(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ba4d0",
   "metadata": {},
   "source": [
    "### Animation 3: Activation Functions in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19827598",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%manim -qm -v WARNING ActivationFunctions\n",
    "\n",
    "class ActivationFunctions(Scene):\n",
    "    def construct(self):\n",
    "        # Title\n",
    "        title = Text(\"Activation Functions: The Neuron's Decision Maker\", font_size=36, color=BLUE)\n",
    "        self.play(Write(title))\n",
    "        self.wait(1)\n",
    "        self.play(title.animate.to_edge(UP))\n",
    "        \n",
    "        # Create axes\n",
    "        axes = Axes(\n",
    "            x_range=[-5, 5, 1],\n",
    "            y_range=[-0.5, 1.5, 0.5],\n",
    "            x_length=8,\n",
    "            y_length=4,\n",
    "            axis_config={\"color\": GREY}\n",
    "        )\n",
    "        \n",
    "        x_label = Text(\"Input (z)\", font_size=20).next_to(axes.x_axis, DOWN)\n",
    "        y_label = Text(\"Output\", font_size=20).next_to(axes.y_axis, LEFT)\n",
    "        \n",
    "        self.play(Create(axes), Write(x_label), Write(y_label))\n",
    "        \n",
    "        # Sigmoid function\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        # Create sigmoid curve\n",
    "        sigmoid_curve = axes.plot(sigmoid, x_range=[-5, 5], color=BLUE)\n",
    "        \n",
    "        sigmoid_label = Text(\"Sigmoid Function\", font_size=24, color=BLUE)\n",
    "        sigmoid_label.to_edge(LEFT).shift(UP*2)\n",
    "        \n",
    "        self.play(Create(sigmoid_curve), Write(sigmoid_label))\n",
    "        \n",
    "        # Show key points\n",
    "        points_to_show = [-3, -1, 0, 1, 3]\n",
    "        dots = []\n",
    "        labels = []\n",
    "        \n",
    "        for x_val in points_to_show:\n",
    "            y_val = sigmoid(x_val)\n",
    "            point = axes.coords_to_point(x_val, y_val)\n",
    "            \n",
    "            dot = Dot(point, color=RED, radius=0.08)\n",
    "            label = Text(f\"({x_val}, {y_val:.2f})\", font_size=12, color=WHITE)\n",
    "            label.next_to(dot, UP, buff=0.1)\n",
    "            \n",
    "            dots.append(dot)\n",
    "            labels.append(label)\n",
    "        \n",
    "        # Animate points\n",
    "        for dot, label in zip(dots, labels):\n",
    "            self.play(Create(dot), Write(label), run_time=0.5)\n",
    "        \n",
    "        # Explanations\n",
    "        explanations = [\n",
    "            \"Large negative inputs ‚Üí Close to 0\",\n",
    "            \"Zero input ‚Üí Exactly 0.5\", \n",
    "            \"Large positive inputs ‚Üí Close to 1\",\n",
    "            \"Smooth transition (differentiable)\"\n",
    "        ]\n",
    "        \n",
    "        explanation_text = Text(\"Key Properties:\", font_size=20, color=YELLOW)\n",
    "        explanation_text.to_edge(DOWN).shift(UP*2)\n",
    "        self.play(Write(explanation_text))\n",
    "        \n",
    "        for i, exp in enumerate(explanations):\n",
    "            exp_text = Text(f\"‚Ä¢ {exp}\", font_size=16, color=WHITE)\n",
    "            exp_text.next_to(explanation_text, DOWN, buff=0.3)\n",
    "            exp_text.shift(DOWN * i * 0.4)\n",
    "            self.play(Write(exp_text), run_time=0.8)\n",
    "        \n",
    "        # Show decision boundary\n",
    "        decision_line = DashedLine(\n",
    "            axes.coords_to_point(0, -0.5),\n",
    "            axes.coords_to_point(0, 1.5),\n",
    "            color=GREEN\n",
    "        )\n",
    "        \n",
    "        decision_label = Text(\"Decision\\nBoundary\", font_size=14, color=GREEN)\n",
    "        decision_label.next_to(decision_line, RIGHT)\n",
    "        \n",
    "        self.play(Create(decision_line), Write(decision_label))\n",
    "        \n",
    "        # Final insight\n",
    "        insight = Text(\n",
    "            \"Sigmoid converts any number to a probability-like value!\",\n",
    "            font_size=18, color=YELLOW\n",
    "        )\n",
    "        insight.to_edge(DOWN)\n",
    "        \n",
    "        self.play(Write(insight))\n",
    "        self.wait(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457d6a7",
   "metadata": {},
   "source": [
    "## Step 8: Real-World Example - House Price Prediction\n",
    "\n",
    "Let's use our neuron to solve a real problem: predicting if a house is expensive based on its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e545ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world example: House price prediction\n",
    "def house_price_neuron():\n",
    "    \"\"\"\n",
    "    Use our neuron to predict if a house is expensive.\n",
    "    Inputs: [size_sqft, bedrooms, age_years]\n",
    "    Output: probability that house is expensive (>$500k)\n",
    "    \"\"\"\n",
    "    print(\"üè† HOUSE PRICE PREDICTION NEURON\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create our house price neuron\n",
    "    house_neuron = SimpleNeuron(num_inputs=3)\n",
    "    \n",
    "    # Set weights based on our intuition:\n",
    "    # - Larger houses are more expensive (positive weight)\n",
    "    # - More bedrooms = more expensive (positive weight)\n",
    "    # - Older houses might be less expensive (negative weight)\n",
    "    house_neuron.set_weights_and_bias(\n",
    "        weights=[0.001, 0.3, -0.05],  # size, bedrooms, age\n",
    "        bias=-1.5  # Generally lean towards \"not expensive\"\n",
    "    )\n",
    "    \n",
    "    # Test houses\n",
    "    test_houses = [\n",
    "        {\"size\": 1200, \"bedrooms\": 2, \"age\": 30, \"description\": \"Small older home\"},\n",
    "        {\"size\": 2500, \"bedrooms\": 4, \"age\": 5, \"description\": \"Large new home\"},\n",
    "        {\"size\": 1800, \"bedrooms\": 3, \"age\": 15, \"description\": \"Medium family home\"},\n",
    "        {\"size\": 3500, \"bedrooms\": 5, \"age\": 2, \"description\": \"Luxury mansion\"},\n",
    "        {\"size\": 900, \"bedrooms\": 1, \"age\": 50, \"description\": \"Tiny old cottage\"}\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nPredicting house prices...\\n\")\n",
    "    print(f\"{'Description':20} | {'Size':6} | {'Beds':4} | {'Age':3} | {'Probability':11} | {'Prediction':10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for house in test_houses:\n",
    "        # Prepare inputs (normalize size by dividing by 1000)\n",
    "        inputs = [house[\"size\"], house[\"bedrooms\"], house[\"age\"]]\n",
    "        \n",
    "        # Get prediction\n",
    "        probability, raw_sum = house_neuron.forward(inputs)\n",
    "        \n",
    "        # Convert to binary prediction\n",
    "        prediction = \"Expensive\" if probability > 0.5 else \"Affordable\"\n",
    "        \n",
    "        print(f\"{house['description']:20} | {house['size']:4d}sq | {house['bedrooms']:2d}br | {house['age']:2d}y | {probability:9.3f} | {prediction:10}\")\n",
    "    \n",
    "    print(\"\\nüí° How the neuron 'thinks':\")\n",
    "    print(\"‚Ä¢ Size weight (0.001): Bigger houses add to expense score\")\n",
    "    print(\"‚Ä¢ Bedroom weight (0.3): More bedrooms add significantly\")\n",
    "    print(\"‚Ä¢ Age weight (-0.05): Older houses reduce expense score\")\n",
    "    print(\"‚Ä¢ Bias (-1.5): Default assumption is 'affordable'\")\n",
    "    print(\"‚Ä¢ Sigmoid output: Converts score to probability\")\n",
    "\n",
    "house_price_neuron()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43346046",
   "metadata": {},
   "source": [
    "## Step 9: Visualizing Decision Boundaries\n",
    "\n",
    "Let's see how our neuron divides the input space into \"expensive\" and \"affordable\" regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_decision_boundary():\n",
    "    \"\"\"\n",
    "    Create a 2D visualization of how the neuron makes decisions.\n",
    "    We'll fix one input and vary the other two.\n",
    "    \"\"\"\n",
    "    # Create a simpler 2-input neuron for visualization\n",
    "    simple_neuron = SimpleNeuron(num_inputs=2)\n",
    "    simple_neuron.set_weights_and_bias([1.5, -0.8], bias=-1.0)\n",
    "    \n",
    "    # Create grid of input values\n",
    "    x1_range = np.linspace(-3, 4, 100)\n",
    "    x2_range = np.linspace(-3, 4, 100)\n",
    "    X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "    \n",
    "    # Calculate neuron output for each point\n",
    "    Z = np.zeros_like(X1)\n",
    "    for i in range(len(x1_range)):\n",
    "        for j in range(len(x2_range)):\n",
    "            output, _ = simple_neuron.forward([X1[i,j], X2[i,j]])\n",
    "            Z[i,j] = output\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add contour plot\n",
    "    fig.add_trace(go.Contour(\n",
    "        x=x1_range,\n",
    "        y=x2_range,\n",
    "        z=Z,\n",
    "        colorscale='RdYlBu',\n",
    "        showscale=True,\n",
    "        colorbar=dict(title=\"Neuron Output\"),\n",
    "        contours=dict(\n",
    "            start=0,\n",
    "            end=1,\n",
    "            size=0.1\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Add decision boundary (output = 0.5)\n",
    "    fig.add_trace(go.Contour(\n",
    "        x=x1_range,\n",
    "        y=x2_range,\n",
    "        z=Z,\n",
    "        contours=dict(\n",
    "            start=0.5,\n",
    "            end=0.5,\n",
    "            size=0.1\n",
    "        ),\n",
    "        line=dict(color='black', width=4),\n",
    "        showscale=False,\n",
    "        name=\"Decision Boundary\"\n",
    "    ))\n",
    "    \n",
    "    # Add some sample points\n",
    "    sample_points = [[-1, 2], [2, 1], [0, 0], [3, -1], [-2, -1]]\n",
    "    \n",
    "    for i, point in enumerate(sample_points):\n",
    "        output, _ = simple_neuron.forward(point)\n",
    "        color = 'red' if output > 0.5 else 'blue'\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[point[0]],\n",
    "            y=[point[1]],\n",
    "            mode='markers',\n",
    "            marker=dict(size=12, color=color, line=dict(color='white', width=2)),\n",
    "            name=f\"Point {i+1} (out={output:.2f})\",\n",
    "            showlegend=True\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Neuron Decision Boundary Visualization\",\n",
    "        xaxis_title=\"Input 1 (x1)\",\n",
    "        yaxis_title=\"Input 2 (x2)\",\n",
    "        width=700,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Show the decision boundary\n",
    "boundary_plot = visualize_decision_boundary()\n",
    "boundary_plot.show()\n",
    "\n",
    "print(\"\\nüéØ Understanding the Decision Boundary:\")\n",
    "print(\"‚Ä¢ Blue region: Neuron outputs < 0.5 (Class 0)\")\n",
    "print(\"‚Ä¢ Red region: Neuron outputs > 0.5 (Class 1)\")\n",
    "print(\"‚Ä¢ Black line: Decision boundary (output = 0.5)\")\n",
    "print(\"‚Ä¢ Single neuron creates LINEAR decision boundary\")\n",
    "print(\"‚Ä¢ Points are colored by their actual predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96560fc8",
   "metadata": {},
   "source": [
    "## Step 10: Key Takeaways\n",
    "\n",
    "Let's summarize what we've learned about single neurons and prepare for the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß† NEURAL NETWORKS PART 1: SINGLE NEURON - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"‚úÖ What we learned:\")\n",
    "print(\"‚Ä¢ A neuron is a mathematical function that processes inputs\")\n",
    "print(\"‚Ä¢ Key components: weights, bias, activation function\")\n",
    "print(\"‚Ä¢ Weights determine input importance\")\n",
    "print(\"‚Ä¢ Bias shifts the decision threshold\")\n",
    "print(\"‚Ä¢ Activation functions (like sigmoid) add non-linearity\")\n",
    "print(\"‚Ä¢ Single neurons create linear decision boundaries\")\n",
    "print(\"‚Ä¢ Neurons can solve simple classification problems\")\n",
    "print()\n",
    "print(\"üîß What we built:\")\n",
    "print(\"‚Ä¢ Complete neuron class from scratch\")\n",
    "print(\"‚Ä¢ Weather decision system\")\n",
    "print(\"‚Ä¢ House price predictor\")\n",
    "print(\"‚Ä¢ Decision boundary visualizations\")\n",
    "print(\"‚Ä¢ Beautiful Manim animations\")\n",
    "print()\n",
    "print(\"üöÄ Coming up in Part 2:\")\n",
    "print(\"‚Ä¢ Training neurons to learn from data\")\n",
    "print(\"‚Ä¢ Gradient descent optimization\")\n",
    "print(\"‚Ä¢ Loss functions and backpropagation\")\n",
    "print(\"‚Ä¢ Making neurons smarter through learning\")\n",
    "print()\n",
    "print(\"üéØ Key insight: A single neuron is like a smart linear classifier\")\n",
    "print(\"   that can learn patterns in data!\")\n",
    "print()\n",
    "print(\"Ready for Part 2? Let's teach our neuron to learn! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8378e7b3",
   "metadata": {},
   "source": [
    "## How to Run the Animations\n",
    "\n",
    "To run these Manim animations:\n",
    "\n",
    "1. **Install Manim** if you haven't already:\n",
    "   ```bash\n",
    "   pip install manim\n",
    "   ```\n",
    "\n",
    "2. **Run each animation cell** one by one. The `%%manim` magic command will:\n",
    "   - Generate the animation\n",
    "   - Save it as a video file\n",
    "   - Display it in the notebook\n",
    "\n",
    "3. **Animation Settings**: Medium quality (`-qm`) for good balance of visual quality and rendering speed.\n",
    "\n",
    "**Note**: First-time Manim setup might take a moment to install dependencies.\n",
    "\n",
    "---\n",
    "\n",
    "**üéì Congratulations!** You've built your first artificial neuron from scratch and understand how it processes information. In the next notebook, we'll teach it to learn from data!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
